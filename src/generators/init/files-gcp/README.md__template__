# <%= className %> Cache Server

<% if (provider === 'gcp') { %>A high-performance Nx cache server with Google Cloud Storage backend.<% } else { %>A high-performance Nx cache server with AWS S3 backend.<% } %><% if (includeMetrics) { %> Includes Prometheus metrics for monitoring and observability.<% } %>

## Features

- ‚úÖ Nx cache API compatible
- üöÄ High-performance streaming
<% if (provider === 'gcp') { %>- ‚òÅÔ∏è Google Cloud Storage backend<% } else { %>- ‚òÅÔ∏è AWS S3 backend<% } %>
- üîê Bearer token authentication
- üìä Structured logging with Pino<% if (includeMetrics) { %>
- üìà Prometheus metrics endpoint<% } %><% if (includeDocker) { %>
- üê≥ Docker ready<% } %>
- üîÑ Graceful shutdown
- ‚ö° Express.js based

## Quick Start

### 1. Install Dependencies

```bash
npm install
```

### 2. Environment Variables

<% if (provider === 'gcp') { %>Create a `.env` file with the following variables:

```env
# Required
NX_CACHE_ACCESS_TOKEN=your-secure-token-here
GOOGLE_CLOUD_PROJECT_ID=your-gcp-project-id
GCS_BUCKET_NAME=your-gcs-bucket-name

# Optional
PORT=3000
LOG_LEVEL=info
GOOGLE_CLOUD_KEY_FILE=/path/to/service-account.json
```

#### Google Cloud Authentication

You can authenticate using either:

1. **Service Account Key File** (recommended for local development):
   ```bash
   export GOOGLE_CLOUD_KEY_FILE=/path/to/your/service-account.json
   ```

2. **Application Default Credentials** (recommended for production):
   ```bash
   gcloud auth application-default login
   ```<% } else { %>Create a `.env` file with the following variables:

```env
# Required
NX_CACHE_ACCESS_TOKEN=your-secure-token-here
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key
S3_BUCKET_NAME=your-bucket-name

# Optional
PORT=3000
LOG_LEVEL=info
S3_ENDPOINT_URL=https://s3.us-east-1.amazonaws.com
```

#### AWS Authentication

You can authenticate using:

1. **Environment Variables** (as shown above)
2. **AWS Profile**:
   ```bash
   export AWS_PROFILE=your-profile-name
   ```
3. **IAM Role** (when running on EC2/ECS)<% } %>

### 3. Start the Server

```bash
# Development (with auto-reload)
npm run dev

# Production
npm start
```

## API Endpoints

### Health Check
```
GET /health
```
Returns `200 OK` if the server is healthy.

<% if (includeMetrics) { %>### Metrics
```
GET /metrics
```
Returns Prometheus metrics in text format.

<% } %>### Cache Upload
```
PUT /v1/cache/:hash
Authorization: Bearer <token>
Content-Type: application/octet-stream
```
Upload cache artifact. Returns `409` if hash already exists.

### Cache Download
```
GET /v1/cache/:hash
Authorization: Bearer <token>
```
Download cache artifact. Returns `404` if not found.

## Configuration

### Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `NX_CACHE_ACCESS_TOKEN` | Yes | - | Bearer token for authentication |<% if (provider === 'gcp') { %>
| `GOOGLE_CLOUD_PROJECT_ID` | Yes | - | GCP Project ID |
| `GCS_BUCKET_NAME` | Yes | - | Google Cloud Storage bucket name |
| `GOOGLE_CLOUD_KEY_FILE` | No | - | Path to service account JSON file |<% } else { %>
| `AWS_REGION` | Yes | `us-east-1` | AWS region |
| `AWS_ACCESS_KEY_ID` | Yes | - | AWS access key |
| `AWS_SECRET_ACCESS_KEY` | Yes | - | AWS secret key |
| `S3_BUCKET_NAME` | Yes | - | S3 bucket name |
| `S3_ENDPOINT_URL` | No | - | Custom S3 endpoint URL |<% } %>
| `PORT` | No | `3000` | Server port |
| `LOG_LEVEL` | No | `info` | Log level (trace, debug, info, warn, error) |
| `NODE_ENV` | No | `development` | Node environment |

<% if (includeMetrics) { %>## Monitoring

The server exposes Prometheus metrics at `/metrics` endpoint:

- **HTTP Metrics**: Request duration, request count, status codes
- **Cache Metrics**: Upload/download operations, artifact sizes
- **Authentication Metrics**: Success/failure counts<% if (provider === 'gcp') { %>
- **GCS Metrics**: Operation latencies, success/failure rates<% } else { %>
- **S3 Metrics**: Operation latencies, success/failure rates<% } %>
- **System Metrics**: Memory usage, active connections
- **Error Metrics**: Error counts by type and endpoint

### Grafana Dashboard

A sample Grafana dashboard is available in the `monitoring/` directory.

<% } %>## Usage with Nx

To use this cache server with your Nx workspace, set the following environment variables:

```
NX_SELF_HOSTED_REMOTE_CACHE_SERVER=http://your-server:3000
NX_SELF_HOSTED_REMOTE_CACHE_ACCESS_TOKEN=your-secure-token
```

<% if (includeDocker) { %>## Docker

### Build Image
```bash
docker build -t <%= name %> .
```

### Run Container
```bash
docker run -p 3000:3000 \
  -e NX_CACHE_ACCESS_TOKEN=your-token \<% if (provider === 'gcp') { %>
  -e GOOGLE_CLOUD_PROJECT_ID=your-project \
  -e GCS_BUCKET_NAME=your-bucket \<% } else { %>
  -e AWS_REGION=us-east-1 \
  -e AWS_ACCESS_KEY_ID=your-key \
  -e AWS_SECRET_ACCESS_KEY=your-secret \
  -e S3_BUCKET_NAME=your-bucket \<% } %>
  <%= name %>
```

<% } %>## Development

### Project Structure
```
src/
‚îú‚îÄ‚îÄ main.js          # Main server file
‚îú‚îÄ‚îÄ package.json     # Dependencies and scripts
‚îî‚îÄ‚îÄ README.md        # This file
<% if (includeDocker) %>Dockerfile          # Docker configuration
<% } %>.env.example        # Environment template
```

### Scripts
- `npm start` - Start production server
- `npm run dev` - Start development server with auto-reload

## Security Considerations

1. **Use strong tokens**: Generate cryptographically secure tokens
2. **Network security**: Use HTTPS in production
3. **Access control**: Restrict access to the cache server<% if (provider === 'gcp') { %>
4. **GCS permissions**: Use minimal required permissions
5. **Service account**: Use dedicated service accounts<% } else { %>
4. **S3 permissions**: Use minimal required IAM permissions
5. **AWS credentials**: Use IAM roles when possible<% } %>

## License

MIT
